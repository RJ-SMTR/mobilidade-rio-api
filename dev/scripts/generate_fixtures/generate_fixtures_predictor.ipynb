{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate fixtures\n",
    "\n",
    "How to use it:\n",
    "\n",
    "We have 3 steps:\n",
    "1. load gtfs files\n",
    "2. filter gtfs data\n",
    "3. save fixtures\n",
    "4. realtime api sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load GTFS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "gtfs_folder = glob(f\"../manage_db/fixtures/pontos/\")[0]\n",
    "\n",
    "gtfs = {\n",
    "    \"agency\": pd.read_csv(f\"{gtfs_folder}/agency.txt\"),\n",
    "    \"stop_times\": pd.read_csv(f\"{gtfs_folder}/stop_times.txt\"),\n",
    "    \"stops\": pd.read_csv(f\"{gtfs_folder}/stops.txt\"),\n",
    "    \"trips\": pd.read_csv(f\"{gtfs_folder}/trips.txt\"),\n",
    "    \"frequencies\": pd.read_csv(f\"{gtfs_folder}/frequencies.txt\"),\n",
    "    \"routes\": pd.read_csv(f\"{gtfs_folder}/routes.txt\"),\n",
    "    \"shapes\": pd.read_csv(f\"{gtfs_folder}/shapes.txt\"),\n",
    "    \"calendar\": pd.read_csv(f\"{gtfs_folder}/calendar.txt\"),\n",
    "    \"calendar_dates\": pd.read_csv(f\"{gtfs_folder}/calendar_dates.txt\"),\n",
    "}\n",
    "\n",
    "gtfs_to_save: Dict[str, pd.DataFrame] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Filter GTFS data\n",
    "\n",
    "GTFS diagram for reference:\n",
    "![GTFS diagram - research gate](https://www.researchgate.net/profile/Milos-Jovanovik/publication/263853949/figure/fig1/AS:296062309945345@1447598163690/The-GTFS-Schema-for-the-data-from-JSP-Skopje.png)\n",
    "Source: [Open Public Transport Data in Macedonia - Research Gate](https://www.researchgate.net/figure/The-GTFS-Schema-for-the-data-from-JSP-Skopje_fig1_263853949)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'agency': 5,\n",
       " 'calendar_dates': 10,\n",
       " 'calendar': 10,\n",
       " 'frequencies': 10,\n",
       " 'routes': 10,\n",
       " 'shapes': 10,\n",
       " 'stop_times': 6,\n",
       " 'stops': 2,\n",
       " 'trips': 10}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# copy to filter\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "agency = gtfs['agency'].copy()\n",
    "st = gtfs['stop_times'].copy()\n",
    "stops = gtfs['stops'].copy()\n",
    "trips = gtfs['trips'].copy()\n",
    "frequencies = gtfs['frequencies'].copy()\n",
    "routes = gtfs['routes'].copy()\n",
    "shapes = gtfs['shapes'].copy()\n",
    "calendar = gtfs['calendar'].copy()\n",
    "cd = gtfs['calendar_dates'].copy()\n",
    "\n",
    "\n",
    "# filter utils\n",
    "\n",
    "def get_stop_and_its_platforms(stops: pd.DataFrame, codes: List[str], limit: int = -1):\n",
    "    s = stops.copy()\n",
    "    stop_code = s['stop_code'].isin(codes)\n",
    "    response = s[(stop_code) | (\n",
    "        s['parent_station'].isin(s[stop_code]['stop_id']))]\n",
    "    if limit >= 0:\n",
    "        response = response.head(limit)\n",
    "    response = response.sort_values(by='stop_code')\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_realtime_inputs():\n",
    "    url = os.environ.get(\n",
    "        \"API_REALTIME\", \"https://dados.mobilidade.rio/gps/brt\")\n",
    "    _response = requests.get(url, timeout=5)\n",
    "    data: List[dict] = _response.json()[\"veiculos\"]\n",
    "    response = []\n",
    "    keys = []\n",
    "    for i in data:\n",
    "        if i['linha'] not in keys:\n",
    "            response += [{\n",
    "                'trip_short_name': i['linha'],\n",
    "                'direction_id': 1 if i['sentido'] == \"volta\" else 0,\n",
    "            }]\n",
    "            keys += [i['linha']]\n",
    "    return response\n",
    "\n",
    "\n",
    "def filter_stops():\n",
    "    global stops, trips, st\n",
    "    # inputs = get_realtime_inputs()\n",
    "    # tsn = [i['trip_short_name'] for i in inputs]\n",
    "    # trips = trips[trips['trip_short_name'].isin(tsn)]\n",
    "    # st = st[st['trip_id'].isin(trips['trip_id'])]\n",
    "    # stops = stops[stops['stop_id'].isin(st['stop_id'])]\n",
    "    # codes = stops[stops['stop_code'].notnull()]['stop_code'].to_list()[:1]\n",
    "    # print('codes',codes)\n",
    "    stops = get_stop_and_its_platforms(stops, ['TOTAL'], 2)\n",
    "\n",
    "\n",
    "def filter_fk(limit: int = -1):\n",
    "    \"\"\"keep only rows with valid fk\"\"\"\n",
    "    global st, stops, trips, frequencies, routes, shapes, calendar, cd\n",
    "\n",
    "    if limit >= 0:\n",
    "        routes = routes.head(limit)\n",
    "        stops = stops.head(limit)\n",
    "        calendar = calendar.head(limit)\n",
    "\n",
    "    shapes_dup = gtfs['shapes'][gtfs['shapes'].duplicated(\n",
    "        subset=['shape_id'], keep=False)]\n",
    "    shapes = shapes_dup\n",
    "\n",
    "    trips = trips[\n",
    "        (trips['route_id'].isin(routes['route_id']))\n",
    "        & (trips['service_id'].isin(calendar['service_id']))\n",
    "        & (trips['shape_id'].isin(shapes['shape_id']))\n",
    "    ]\n",
    "    if limit >= 0:\n",
    "        trips = trips.head(limit)\n",
    "\n",
    "    st = st[\n",
    "        (st['stop_id'].isin(stops['stop_id']))\n",
    "        & (st['trip_id'].isin(trips['trip_id']))\n",
    "    ]\n",
    "    trips = trips[\n",
    "        (trips['route_id'].isin(routes['route_id']))\n",
    "        & (trips['service_id'].isin(calendar['service_id']))\n",
    "        & (trips['shape_id'].isin(shapes['shape_id']))\n",
    "    ]\n",
    "\n",
    "    frequencies = frequencies[frequencies['trip_id'].isin(trips['trip_id'])]\n",
    "\n",
    "    if limit >= 0:\n",
    "        limit_results(limit)\n",
    "\n",
    "\n",
    "def limit_results(max: int):\n",
    "    global st, stops, trips, frequencies, routes, shapes, calendar, cd\n",
    "    st = st.head(max)\n",
    "    stops = stops.head(max)\n",
    "    trips = trips.head(max)\n",
    "    frequencies = frequencies.head(max)\n",
    "    routes = routes.head(max)\n",
    "    shapes = shapes.head(max)\n",
    "    calendar = calendar.head(max)\n",
    "    cd = cd.head(max)\n",
    "\n",
    "\n",
    "def patch_col(dest: pd.DataFrame, src: pd.DataFrame, col: str):\n",
    "    i = 0\n",
    "    src = src.copy().reset_index(drop=True)\n",
    "    dest = dest.copy().reset_index(drop=True)\n",
    "    for _, _ in dest.iterrows():\n",
    "        dest.at[i, col] = src.at[i % len(src), col]\n",
    "        i += 1\n",
    "    return dest\n",
    "\n",
    "\n",
    "def patch_rows():\n",
    "    \"\"\"Modify values to make a suitable data mock\"\"\"\n",
    "    global st, stops, trips, frequencies, routes, shapes, calendar, cd\n",
    "    # fk\n",
    "    st = patch_col(st, trips, 'trip_id')\n",
    "    trips = patch_col(trips, routes, 'route_id')\n",
    "    trips = patch_col(trips, calendar, 'service_id')\n",
    "    trips = patch_col(trips, shapes, 'shape_id')\n",
    "    frequencies = patch_col(frequencies, trips, 'trip_id')\n",
    "    # trip_short_name\n",
    "    tsn = ['0', '10', '11', '12', '13', '14', '17', '18', '19', '20', '22', '25',\n",
    "           '29', '31', '35', '38', '40', '41', '42', '43', '46', '50', '51', '52', '53']\n",
    "    for i, _ in trips.iterrows():\n",
    "        trips.at[i, 'trip_short_name'] = tsn[i % len(tsn)]\n",
    "    st = st.replace(0, 1)\n",
    "\n",
    "\n",
    "# run filters\n",
    "filter_stops()\n",
    "filter_fk()\n",
    "\n",
    "max = 10\n",
    "st = st.head(max)\n",
    "stops = stops.head(max)\n",
    "trips = trips.head(max)\n",
    "frequencies = frequencies.head(max)\n",
    "routes = routes.head(max)\n",
    "shapes = shapes.head(max)\n",
    "calendar = calendar.head(max)\n",
    "cd = cd.head(max)\n",
    "\n",
    "patch_rows()\n",
    "\n",
    "# save\n",
    "gtfs_to_save = {\n",
    "    'agency': {'table': agency, 'pk': \"agency_id\", 'model': \"pontos.agency\"},\n",
    "    'calendar_dates': {'table': cd, 'pk': None, 'model': \"pontos.calendardates\"},\n",
    "    'calendar': {'table': calendar, 'pk': \"service_id\", 'model': \"pontos.calendar\"},\n",
    "    'frequencies': {'table': frequencies, 'pk': None, 'model': \"pontos.frequencies\"},\n",
    "    'routes': {'table': routes, 'pk': \"route_id\", 'model': \"pontos.routes\"},\n",
    "    'shapes': {'table': shapes, 'pk': None, 'model': \"pontos.shapes\"},\n",
    "    'stop_times': {'table': st, 'pk': None, 'model': \"pontos.stoptimes\"},\n",
    "    'stops': {'table': stops, 'pk': \"stop_id\", 'model': \"pontos.stops\"},\n",
    "    'trips': {'table': trips, 'pk': \"trip_id\", 'model': \"pontos.trips\"},\n",
    "}\n",
    "\n",
    "# log\n",
    "print(\"result:\")\n",
    "display({k: len(v['table']) for k, v in gtfs_to_save.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Save as fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving agency (5) ... \t0:00:00.003502s\n",
      "Saving calendar_dates (10) ... \t0:00:00.003498s\n",
      "Saving calendar (10) ... \t0:00:00.005023s\n",
      "Saving frequencies (10) ... \t0:00:00.003003s\n",
      "Saving routes (10) ... \t0:00:00.005038s\n",
      "Saving shapes (10) ... \t0:00:00.003489s\n",
      "Saving stop_times (6) ... \t0:00:00.003529s\n",
      "Saving stops (2) ... \t0:00:00.002002s\n",
      "Saving trips (10) ... \t0:00:00.003506s\n",
      "\n",
      "Done (2024-01-13 03:32:55.206184) \t0:00:00.036614s\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from os import path\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "fixtures_folder = glob(\n",
    "    f\"../../../mobilidade_rio/mobilidade_rio/predictor/tests/fixtures\")[0]\n",
    "\n",
    "generate_start = dt.now()\n",
    "for name, info in gtfs_to_save.items():\n",
    "    fixtures: List[dict] = []\n",
    "    table: pd.DataFrame = info['table']\n",
    "\n",
    "    now = dt.now()\n",
    "    print(f\"Saving {name} ({len(table)}) ...\", end='')\n",
    "\n",
    "    # treat table\n",
    "    table = table.replace({np.nan: None})\n",
    "    date_cols = [i for i in table.columns.to_list(\n",
    "    ) if i in ['date', 'start_date', 'end_date']]\n",
    "    for col in date_cols:\n",
    "        table[col] = table[col].astype(\n",
    "            str).apply(lambda n: f\"{n[:4]}-{n[4:6]}-{n[6:]}\")\n",
    "\n",
    "    # generate\n",
    "    for index, row in table.iterrows():\n",
    "        info_pk = info['pk']\n",
    "        if info_pk is not None:\n",
    "            pk = str(row[info_pk])\n",
    "        else:\n",
    "            pk = str(index + 1)\n",
    "        treated_row = row.replace({np.nan: None})\n",
    "        fixture = {\n",
    "            'model': info['model'],\n",
    "            'pk': pk,\n",
    "            'fields': treated_row.to_dict(),\n",
    "        }\n",
    "        fixtures.append(fixture)\n",
    "\n",
    "    # save\n",
    "    save_filepath = path.join(fixtures_folder, f\"{name}.json\")\n",
    "    with open(save_filepath, 'w') as json_file:\n",
    "        json_file.write(json.dumps(fixtures, indent=4))\n",
    "        print(f\" \\t{dt.now() - now}s\")\n",
    "\n",
    "print(f\"\\nDone ({dt.now()}) \\t{dt.now() - generate_start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Realtime api sample\n",
    "\n",
    "Get static sample of realtime api data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_realtime.json (249 items) saved! \t18:43:16.024812s\n"
     ]
    }
   ],
   "source": [
    "def get_realtime():\n",
    "    url = os.environ.get(\n",
    "        \"API_REALTIME\", \"https://dados.mobilidade.rio/gps/brt\")\n",
    "    _response = requests.get(url, timeout=5)\n",
    "    data: dict = _response.json()\n",
    "    return data\n",
    "\n",
    "data = get_realtime()\n",
    "data['veiculos'] = data['veiculos'][:int(len(data['veiculos'])/2)]\n",
    "\n",
    "\n",
    "# save\n",
    "data_folder = glob(\n",
    "    f\"../../../mobilidade_rio/mobilidade_rio/predictor/tests/data\")[0]\n",
    "save_filepath = path.join(data_folder, f\"api_realtime.json\")\n",
    "with open(save_filepath, 'w') as json_file:\n",
    "    json_file.write(json.dumps(data))\n",
    "    print(\n",
    "        f\"api_realtime.json ({len(data['veiculos'])} items) saved! \\t{dt.now() - now}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobrio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
